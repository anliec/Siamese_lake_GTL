{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sns.set()\n",
    "con = sqlite3.connect(\"./data.db\")\n",
    "\n",
    "# con.execute(('CREATE TABLE IF NOT EXISTS \"siam\" ('\n",
    "#              '\"ln\" INTEGER,'\n",
    "#              '\"epoch\" INTEGER,'\n",
    "#              '\"val_loss\" REAL,'\n",
    "#              '\"val_categorical_accuracy\" REAL,'\n",
    "#              '\"loss\" REAL,'\n",
    "#              '\"categorical_accuracy\" REAL,'\n",
    "#              '\"use_batch_norm\" TEXT,'\n",
    "#              '\"optimizer\" TEXT,'\n",
    "#              '\"activation\" TEXT,'\n",
    "#              '\"layers\" TEXT,'\n",
    "#              '\"train_size\" INTEGER,'\n",
    "#              '\"reduction_method\" TEXT,'\n",
    "#              '\"number_of_feature\" INTEGER'\n",
    "#              ');'))\n",
    "# con.execute('CREATE INDEX \"RM\" on \"per\" (\"reduction_method\");')\n",
    "# con.execute('CREATE INDEX \"NF\" on \"per\" (\"number_of_feature\");')\n",
    "con.enable_load_extension(True)\n",
    "con.load_extension(\"./extension-functions\")\n",
    "\n",
    "if not os.path.exists(\"graphs\"):\n",
    "    os.makedirs(\"graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/GTL/nsix/Python3/lib/python3.6/site-packages/pandas/core/generic.py:1534: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "csv_paths = glob.glob('runs_results/*/history.csv')\n",
    "\n",
    "if len(csv_paths) > 0:\n",
    "    con.execute('drop table siam')\n",
    "    for file in csv_paths:\n",
    "        df = pd.read_csv(file)\n",
    "        df.to_sql('siam', con, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_z_query(z_name: str, filters: dict):\n",
    "    where_close = \"\"\n",
    "    first_key = True\n",
    "    for k, lf in filters.items():\n",
    "        if first_key:\n",
    "            first_key = False\n",
    "        else:\n",
    "            where_close += \"AND \"\n",
    "        where_close += \"(\"\n",
    "        first = True\n",
    "        for v in lf:\n",
    "            if not first:\n",
    "                where_close += \" OR \"\n",
    "            else:\n",
    "                first = False\n",
    "            where_close += str(k)+\"='\"+str(v)+\"'\"\n",
    "        where_close += \") \"\n",
    "    query = \"SELECT DISTINCT \"+z_name+\" FROM per\"\n",
    "    if where_close != \"\":\n",
    "        query += \" WHERE \" + where_close\n",
    "    return query\n",
    "\n",
    "\n",
    "def generate_sql_xy_query(x_name: str, y_name: str, z_name: str, z_value, filters: dict, x_limit):\n",
    "    where_close = z_name+\" = '\"+str(z_value)+\"' \"\n",
    "    for k, lf in filters.items():\n",
    "        where_close += \"AND (\"\n",
    "        first = True\n",
    "        for v in lf:\n",
    "            if not first:\n",
    "                where_close += \" OR \"\n",
    "            else:\n",
    "                first = False\n",
    "            where_close += str(k)+\"='\"+str(v)+\"'\"\n",
    "        where_close += \") \"\n",
    "    if x_limit > 0:\n",
    "        where_close += \"AND \" + x_name + \" < \" + str(x_limit) + \" \"\n",
    "    query = (\"SELECT \" + x_name + \",\"\n",
    "             \"min(\" + y_name + \") as min,\"\n",
    "             \"max(\" + y_name + \") as max,\"\n",
    "             \"median(\" + y_name + \") as median,\"\n",
    "             \"avg(\" + y_name + \") as mean \"\n",
    "             \"FROM per \")\n",
    "    if where_close != \"\":\n",
    "        query += \"WHERE \" + where_close\n",
    "    query += \"GROUP BY \" + x_name\n",
    "    return query\n",
    "\n",
    "\n",
    "def consolidate_data_from_db(con, x_name: str, y_name: str, z_name: str, filters: dict, x_limit=-1):\n",
    "    z_value_df = pd.read_sql_query(generate_sql_z_query(z_name, filters), con)\n",
    "    cd = dict()\n",
    "    for i in z_value_df.get(z_name):\n",
    "        query = generate_sql_xy_query(x_name, y_name, z_name, i, filters, x_limit)\n",
    "        print(\"Selecting data for\", z_name, \"=\", i)\n",
    "        # print(query)\n",
    "        cd[i] = pd.read_sql_query(query, con)\n",
    "    return cd\n",
    "\n",
    "\n",
    "def generate_plot(con, x_arg_name, y_arg_name, z_arg_name, filters, save_to_file=True, x_limit=-1, x_name=None, y_name=None):\n",
    "    if x_name is None:\n",
    "        x_name = x_arg_name\n",
    "    if y_name is None:\n",
    "        y_name = y_arg_name\n",
    "        \n",
    "    cd = consolidate_data_from_db(con, x_arg_name, y_arg_name, z_arg_name, filters, x_limit)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.axes()\n",
    "    for a, d in cd.items():\n",
    "        plt.plot(d.get(x_arg_name), d.get('median'), \n",
    "                 label=z_arg_name.replace('_', ' ') + ' = ' + str(a).replace('_', ' '))\n",
    "        # plt.fill_between(d.get(x_arg_name), d.get('mean') - d.get('std'), d.get('mean') + d.get('std'), alpha=0.3)\n",
    "        plt.fill_between(d.get(x_arg_name), d.get('min'), d.get('max'), alpha=0.3)\n",
    "    if y_arg_name == \"val_categorical_accuracy\":\n",
    "        plt.ylabel(\"Validation accuracy\")\n",
    "    else:\n",
    "        plt.ylabel(y_name.replace('_',' '))\n",
    "    plt.xlabel(x_name.replace('_',' '))\n",
    "    plt.legend()\n",
    "    # plt.title(\"Evolution of acuracy acording to the number of training examples\")\n",
    "    if save_to_file:\n",
    "        algo_name = \"all_\"\n",
    "        if \"reduction_method\" in filters.keys():\n",
    "            algo_name = '_'.join(map(str, filters[\"reduction_method\"])) + '_'\n",
    "        layers = \"\"\n",
    "        if \"layers\" in filters.keys():\n",
    "            layers = '_' + '_'.join(map(lambda x: x.replace('(','').replace(')','').replace(',',''), filters[\"layers\"]))\n",
    "        plt.savefig(\"graphs/\"+algo_name+x_name+\"_\"+y_name+\"_\"+z_arg_name+layers+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/GTL/nsix/Python3/lib/python3.6/site-packages/pandas/core/generic.py:1534: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
